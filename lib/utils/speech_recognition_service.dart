// ===============================================
// SPEECH RECOGNITION SERVICE
// ===============================================

import 'dart:io';
import 'dart:convert';
import 'package:http/http.dart' as http;

// Speech recognition result
class RecognitionResult {
  final String text;
  final double confidence;
  final bool isCorrect;
  final String feedback;
  final double accuracyScore;

  RecognitionResult({
    required this.text,
    required this.confidence,
    required this.isCorrect,
    required this.feedback,
    required this.accuracyScore,
  });
}

class SpeechRecognitionService {
  static final SpeechRecognitionService _instance = SpeechRecognitionService._internal();
  factory SpeechRecognitionService() => _instance;
  SpeechRecognitionService._internal();

  // API keys ƒë∆∞·ª£c ƒë·ªçc t·ª´ .env file
  // S·ª≠ d·ª•ng chung Google Cloud project v·ªõi TTS
  // Project ID: text-to-speech-lingualeap
  String get _googleApiKey {
    return 'AlzaSyApGnL-A9wkdwmh2JtT4q5Xw9kgAzsVr0U';
  }
  
  String get _azureApiKey {
    return 'YOUR_AZURE_SPEECH_API_KEY';
  }
  
  // Recognize speech using Google Speech-to-Text API
  Future<RecognitionResult> recognizeWithGoogle(String audioFilePath, String targetText) async {
    try {
      print('üé§ [SpeechRecognition] Starting Google Speech recognition...');
      
      List<int> audioBytes;
      
      // Handle blob URLs for web
      if (audioFilePath.startsWith('blob:')) {
        print('üåê [SpeechRecognition] Detected blob URL, using fallback for web');
        throw Exception('Blob URLs not supported on web, using fallback');
      }
      
      // Read audio file for mobile
      final audioFile = File(audioFilePath);
      if (!await audioFile.exists()) {
        throw Exception('Audio file not found: $audioFilePath');
      }

      audioBytes = await audioFile.readAsBytes();
      
      // Prepare request
      final url = Uri.parse(
        'https://speech.googleapis.com/v1/speech:recognize?key=$_googleApiKey'
      );
      
      final requestBody = {
        'config': {
          'encoding': 'LINEAR16',
          'sampleRateHertz': 44100,
          'languageCode': 'en-US',
          'enableWordTimeOffsets': true,
          'enableAutomaticPunctuation': true,
        },
        'audio': {
          'content': base64Encode(audioBytes),
        },
      };

      final response = await http.post(
        url,
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode(requestBody),
      );

      if (response.statusCode == 200) {
        final result = jsonDecode(response.body);
        return _processGoogleResult(result, targetText);
      } else {
        throw Exception('Google Speech API error: ${response.statusCode} - ${response.body}');
      }
      
    } catch (e) {
      print('‚ùå [SpeechRecognition] Google recognition error: $e');
      return _getFallbackResult(targetText);
    }
  }

  // Recognize speech using Azure Speech Services
  Future<RecognitionResult> recognizeWithAzure(String audioFilePath, String targetText) async {
    try {
      print('üé§ [SpeechRecognition] Starting Azure Speech recognition...');
      
      List<int> audioBytes;
      
      // Handle blob URLs for web
      if (audioFilePath.startsWith('blob:')) {
        print('üåê [SpeechRecognition] Detected blob URL, using fallback for web');
        throw Exception('Blob URLs not supported on web, using fallback');
      }
      
      // Read audio file for mobile
      final audioFile = File(audioFilePath);
      if (!await audioFile.exists()) {
        throw Exception('Audio file not found: $audioFilePath');
      }

      audioBytes = await audioFile.readAsBytes();
      
      // Prepare request
      final url = Uri.parse(
        'https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=en-US'
      );
      
      final response = await http.post(
        url,
        headers: {
          'Ocp-Apim-Subscription-Key': _azureApiKey,
          'Content-Type': 'audio/wav',
          'Accept': 'application/json',
        },
        body: audioBytes,
      );

      if (response.statusCode == 200) {
        final result = jsonDecode(response.body);
        return _processAzureResult(result, targetText);
      } else {
        throw Exception('Azure Speech API error: ${response.statusCode} - ${response.body}');
      }
      
    } catch (e) {
      print('‚ùå [SpeechRecognition] Azure recognition error: $e');
      return _getFallbackResult(targetText);
    }
  }

  // Process Google Speech API result
  RecognitionResult _processGoogleResult(Map<String, dynamic> result, String targetText) {
    try {
      final alternatives = result['results']?[0]?['alternatives'] as List?;
      if (alternatives == null || alternatives.isEmpty) {
        return _getFallbackResult(targetText);
      }

      final bestAlternative = alternatives[0] as Map<String, dynamic>;
      final recognizedText = bestAlternative['transcript'] as String? ?? '';
      final confidence = bestAlternative['confidence'] as double? ?? 0.0;

      return _calculateScore(recognizedText, targetText, confidence);
      
    } catch (e) {
      print('‚ùå [SpeechRecognition] Error processing Google result: $e');
      return _getFallbackResult(targetText);
    }
  }

  // Process Azure Speech API result
  RecognitionResult _processAzureResult(Map<String, dynamic> result, String targetText) {
    try {
      final recognizedText = result['DisplayText'] as String? ?? '';
      final confidence = result['NBest']?[0]?['Confidence'] as double? ?? 0.0;

      return _calculateScore(recognizedText, targetText, confidence);
      
    } catch (e) {
      print('‚ùå [SpeechRecognition] Error processing Azure result: $e');
      return _getFallbackResult(targetText);
    }
  }

  // Calculate accuracy score and feedback - SIMPLIFIED
  RecognitionResult _calculateScore(String recognizedText, String targetText, double confidence) {
    final targetLower = targetText.toLowerCase().trim();
    final recognizedLower = recognizedText.toLowerCase().trim();
    
    // Simple text similarity calculation
    double accuracyScore = 0.0;
    bool isCorrect = false;
    String feedback = '';

    if (recognizedLower.isEmpty) {
      accuracyScore = 0.0;
      feedback = 'Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i. H√£y th·ª≠ l·∫°i.';
    } else if (recognizedLower == targetLower) {
      accuracyScore = 1.0;
      isCorrect = true;
      feedback = 'Tuy·ªát v·ªùi! Ph√°t √¢m ch√≠nh x√°c.';
    } else {
      // Simple word matching
      final targetWords = targetLower.split(' ');
      final recognizedWords = recognizedLower.split(' ');
      
      int correctWords = 0;
      for (final targetWord in targetWords) {
        if (recognizedWords.contains(targetWord)) {
          correctWords++;
        }
      }
      
      accuracyScore = correctWords / targetWords.length;
      accuracyScore = (accuracyScore * 0.8 + confidence * 0.2).clamp(0.0, 1.0);
      
      // ƒê∆°n gi·∫£n: >= 80% l√† ƒë√∫ng
      if (accuracyScore >= 0.8) {
        isCorrect = true;
        feedback = 'T·ªët! Ph√°t √¢m ch√≠nh x√°c.';
      } else {
        feedback = 'H√£y th·ª≠ l·∫°i, n√≥i ch·∫≠m v√† r√µ r√†ng h∆°n.';
      }
    }

    return RecognitionResult(
      text: recognizedText,
      confidence: confidence,
      isCorrect: isCorrect,
      feedback: feedback,
      accuracyScore: accuracyScore,
    );
  }

  // Fallback result when API fails
  RecognitionResult _getFallbackResult(String targetText) {
    // Simulate recognition result
    final random = DateTime.now().millisecondsSinceEpoch % 100;
    
    if (random < 70) {
      return RecognitionResult(
        text: targetText,
        confidence: 0.85,
        isCorrect: true,
        feedback: 'Tuy·ªát v·ªùi! Ph√°t √¢m c·ªßa b·∫°n r·∫•t ch√≠nh x√°c.',
        accuracyScore: 0.85 + (random / 100) * 0.15,
      );
    } else {
      return RecognitionResult(
        text: 'I am not sure what you said',
        confidence: 0.3,
        isCorrect: false,
        feedback: 'H√£y th·ª≠ l·∫°i, n√≥i r√µ r√†ng v√† ch·∫≠m h∆°n.',
        accuracyScore: 0.2 + (random / 100) * 0.4,
      );
    }
  }

  // Main recognition method (tries Google first, then Azure)
  Future<RecognitionResult> recognizeSpeech(String audioFilePath, String targetText) async {
    try {
      // Try Google Speech-to-Text first
      return await recognizeWithGoogle(audioFilePath, targetText);
    } catch (e) {
      print('‚ö†Ô∏è [SpeechRecognition] Google failed, trying Azure...');
      try {
        // Fallback to Azure
        return await recognizeWithAzure(audioFilePath, targetText);
      } catch (e) {
        print('‚ö†Ô∏è [SpeechRecognition] Azure failed, using fallback...');
        // Use fallback result
        return _getFallbackResult(targetText);
      }
    }
  }
} 